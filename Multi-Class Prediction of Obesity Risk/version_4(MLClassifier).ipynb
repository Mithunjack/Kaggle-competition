{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install cmaes","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:28:07.927107Z","iopub.execute_input":"2024-02-13T08:28:07.927509Z","iopub.status.idle":"2024-02-13T08:28:24.392554Z","shell.execute_reply.started":"2024-02-13T08:28:07.927479Z","shell.execute_reply":"2024-02-13T08:28:24.389731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting cmaes\n  Downloading cmaes-0.10.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from cmaes) (1.24.4)\nDownloading cmaes-0.10.0-py3-none-any.whl (29 kB)\nInstalling collected packages: cmaes\nSuccessfully installed cmaes-0.10.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:28:24.394927Z","iopub.execute_input":"2024-02-13T08:28:24.395329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')\n\n# Display the DataFrame\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correct target variable name\ntarget = 'NObeyesdad'\n\n# Splitting the dataset into features and target variable\nX = df.drop(target, axis=1)\ny = df[target]\n\n# Convert categorical features using one-hot encoding\nX = pd.get_dummies(X)\n\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the target variable\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_val_encoded = label_encoder.transform(y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\n# Define the objective function to optimize\ndef objective(trial):\n    # Define hyperparameters to search\n    params = {\n        'hidden_layer_sizes': (trial.suggest_int('n_neurons_layer1', 10, 1000),\n                               trial.suggest_int('n_neurons_layer2', 10, 1000)),\n        'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n        'learning_rate_init': trial.suggest_loguniform('learning_rate_init', 0.0001, 0.1),\n        'max_iter': 1000,  # Maximum number of iterations\n        'random_state': 42,\n        'early_stopping': True  # Enable early stopping\n    }\n\n    # Initialize MLP classifier\n    model = MLPClassifier(**params)\n\n    # Fit the model\n    model.fit(X_train, y_train_encoded)\n\n    # Predict on the validation set\n    y_pred_encoded = model.predict(X_val)\n\n    # Decode the predictions back to original labels\n    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n\n    # Calculate accuracy\n    accuracy = accuracy_score(y_val, y_pred)\n\n    return accuracy\n\n# Define study\nstudy = optuna.create_study(direction='maximize', sampler=optuna.samplers.CmaEsSampler())\n\n# Optimize hyperparameters\nstudy.optimize(objective, n_trials=100)\n\n# Get the best hyperparameters\nbest_params = study.best_params\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Train the final model with the best hyperparameters\nfinal_model = MLPClassifier(**best_params)\nfinal_model.fit(X_train, y_train_encoded)\n\n# Predict on the validation set\ny_pred_encoded = final_model.predict(X_val)\n\n# Decode the predictions back to original labels\ny_pred = label_encoder.inverse_transform(y_pred_encoded)\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_val, y_pred)\nprint('Validation Accuracy:', accuracy)\n0.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the test dataset\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')\n\n# Preprocess the test dataset (e.g., one-hot encoding for categorical features)\ntest_X = pd.get_dummies(test_df)\n\n# Reorder columns in the test dataset to match the order of columns in the training dataset\ntest_X = test_X.reindex(columns=X.columns, fill_value=0)\n\n# Predict on the test set using the final model\ntest_y_pred_encoded = final_model.predict(test_X)\n\n# Decode the predictions back to original labels\ntest_y_pred = label_encoder.inverse_transform(test_y_pred_encoded)\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'NObeyesdad': test_y_pred\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}